.TH teamd.conf 5 "1 September 2012" "libteam"
.SH DESCRIPTION
.PP
teamd uses JSON format configuration. Here comes a list of config options.
.TP
.BR "device " (string, " " mandatory)
Desired name of new team device.

.TP
.BR "hwaddr " (string)
Desired hardware address of new team device. Usual MAC address format is accepted.

.TP
.BR "runner.name " (string, " " mandatory)
Name of team device. There are following runners available:

.BR "broadcast "-
Simple runner using which the team device transmits packets via all ports.

.BR "roundrobin "-
Simple runner using which the team device transmits packets in round-robin fashion.

.BR "activebackup "-
Watches for link changes and selects active port to be used for data transfers.

.BR "loadbalance "-
To do passive load balancing, runner only setups BPF hash function which will determine port for packet transmit. To do active load balancing, runner is moving hashes among available ports trying to reach perfect balance.

.BR "lacp "-
Implements 802.3ad LACP protocol. Can use same TX port selection possibilities as loadbalance runner.

.TP
.BR "link_watch.name "| " ports.PORTIFNAME.link_watch.name " (string)
Name of link watch to be used. There are following link watches available:

.BR "ethtool "-
Uses Libteam lib to get port ethtool state changes.

.BR "arp_ping "-
ARP requests are sent through a port. If an ARP reply is received, the link is considered to be up.

.BR "nsna_ping "-
Similar to the previous, only it uses IPv6 Neighbour Solicitation / Neighbour Announcement mechanism. This is an alternative to arp_ping and becomes handy in pure-IPv6 environments.

.TP
.BR "ports " (object)
List of port NICs to be used in team device.

See examples for more information.

.SH ACTIVE-BACKUP RUNNER SPECIFIC OPTIONS
.TP
.BR "runner.hwaddr_policy " (string)
This defines policy on how hardware addresses of team device and port devices should be set during the team lifetime. Following are available:

.BR "same_all "-
All ports will have always the same hardware address as team device.

.BR "by_active "-
Team device has hardware address of currently active port. This is useful in case that port device is not able to change its hardware address.

.BR "only_active "-
Only active port has hardware address of the team device. The others have their own.

Default:
.BR "same_all"

.TP
.BR "ports.PORTIFNAME.prio " (int)
Port priority. The higher number means higher priority.

Default:
.BR "0"

.TP
.BR "ports.PORTIFNAME.sticky " (bool)
Flag which tells if the port is sticky. That means it does not get de-selected if another port with better priority or parameters becomes available.

Default:
.BR "false"

.TP
.BR "ports.PORTIFNAME.queue_id " (int)
ID of queue which should this port be mapped on.

Default:
.BR "None"

.SH LOAD BALANCE RUNNER SPECIFIC OPTIONS

.TP
.BR "runner.tx_hash " (array)
List of fragment types (strings) which should be used for packet TX hash computation. Here are following available:

.BR "eth "-
Uses source and destination MAC addresses.

.BR "ipv4 "-
Uses source and destination IPv4 addresses.

.BR "ipv6 "-
Uses source and destination IPv6 addresses.

.TP
.BR "runner.tx_balancer.name " (string)
Name of active TX balancer. Active TX balancing is disabled by default. The only value available is
.BR "basic".

Default:
.BR "None"

.TP
.BR "runner.tx_balancer.balancing_interval " (int)
In tenths of second. Interval in what will be rebalancing periodically done.

Default:
.BR "50"

.SH LACP RUNNER SPECIFIC OPTIONS
.TP
.BR "runner.active " (bool)
If active is
.BR "true"
LACPDU frames are send along the configured links by itselt periodically. If not, it acts as "speak when spoken to".

Default:
.BR "true"

.TP
.BR "runner.fast_rate " (bool)
Option specifies the rate in which our link partner is asked to transmit LACPDU packets. If this is
.BR "true"
then packets will be sent once per second. Otherwise they will be sent every 30 seconds.

.TP
.BR "runner.tx_hash " (array)
Same as for load balance runner.

.TP
.BR "runner.tx_balancer.name " (string)
Same as for load balance runner.

.TP
.BR "runner.tx_balancer.balancing_interval " (int)
Same as for load balance runner.

.TP
.BR "runner.sys_prio " (int)
System priority, value can be 0-65535.

Default:
.BR "255"

.TP
.BR "runner.min_ports " (int)
Specifies the minimum number of ports that must be active before asserting carrier in the master interface, value can be 1-255.

Default:
.BR "0"

.TP
.BR "runner.agg_select_policy " (string)
This selects policy on how the aggregators will be selected. Following are available:

.BR "lacp_prio "-
Aggregator with highest priority according to LACP standard will be selected. Aggregator priority is affected by per-port option lacp_prio.

.BR "lacp_prio_stable "-
Same as previous one, only do not replace selected aggregator if is still usable.

.BR "bandwidth "-
Select aggregator with highest total bandwidth.

.BR "count "-
Select aggregator with highest number of ports.

Default:
.BR "lacp_prio"

.TP
.BR "ports.PORTIFNAME.lacp_prio " (int)
Port priority according to LACP standard. The lower number means higher priority.

.TP
.BR "ports.PORTIFNAME.lacp_key " (int)
Port key according to LACP standard. Only ports with the same key are possible to aggregate.

Default:
.BR "0"

.SH ETHTOOL LINK WATCH SPECIFIC OPTIONS
.TP
.BR "link_watch.delay_up "| " ports.PORTIFNAME.link_watch.delay_up " (int)
Value is positive number in milliseconds. It's a delay between link goes up and runner is actually notified about it.

Default:
.BR "0"

.TP
.BR "link_watch.delay_down "| " ports.PORTIFNAME.link_watch.delay_down " (int)
Value is positive number in milliseconds. It's a delay between link goes down and runner is actually notified about it.

Default:
.BR "0"

.SH ARP PING LINK WATCH SPECIFIC OPTIONS
.TP
.BR "link_watch.interval "| " ports.PORTIFNAME.link_watch.interval " (int)
Value is positive number in milliseconds. It's an interval in which ARP requests are sent.

.TP
.BR "link_watch.init_wait "| " ports.PORTIFNAME.link_watch.init_wait " (int)
Value is positive number in milliseconds. It's an delay between link watch initialization and first ARP request send.

Default:
.BR "0"

.TP
.BR "link_watch.missed_max "| " ports.PORTIFNAME.link_watch.missed_max " (int)
Maximum number of missed ARP replies. If this number is overreached, link is reported as down.

.TP
.BR "link_watch.source_host "| " ports.PORTIFNAME.link_watch.source_host " (int)
Hostname to be converted to IP address which will be filled into ARP request as source address.

.TP
.BR "link_watch.target_host "| " ports.PORTIFNAME.link_watch.target_host " (int)
Hostname to be converted to IP address which will be filled into ARP request as destination address.

.TP
.BR "link_watch.validate_active "| " ports.PORTIFNAME.link_watch.validate_active " (bool)
Validate received ARP packets on active ports. If this is not set, all incoming ARP packets will be considered as good reply.

Default:
.BR "false"

.TP
.BR "link_watch.validate_inactive "| " ports.PORTIFNAME.link_watch.validate_inactive " (bool)
Validate received ARP packets on inactive ports. If this is not set, all incoming ARP packets will be considered as good reply.

Default:
.BR "false"

.TP
.BR "link_watch.send_always "| " ports.PORTIFNAME.link_watch.send_always " (bool)
By default, ARP requests are send on active ports only. This option allows to force sending even on inactive ones.

Default:
.BR "false"

.SH NS/NA PING LINK WATCH SPECIFIC OPTIONS
.TP
.BR "link_watch.interval "| " ports.PORTIFNAME.link_watch.interval " (int)
Value is positive number in milliseconds. It's an interval in which NS packets are sent.

.TP
.BR "link_watch.init_wait "| " ports.PORTIFNAME.link_watch.init_wait " (int)
Value is positive number in milliseconds. It's an delay between link watch initialization and first NS packet send.

.TP
.BR "link_watch.missed_max "| " ports.PORTIFNAME.link_watch.missed_max " (int)
Maximum number of missed NA reply packets. If this number is overreached, link is reported as down.

.TP
.BR "link_watch.target_host "| " ports.PORTIFNAME.link_watch.target_host " (int)
Hostname to be converted to IPv6 address which will be filled into NS packet as target address.

.SH EXAMPLES

.nf
{
  "device": "team0",
  "runner": {"name": "roundrobin"},
  "ports": {"eth1": {}, "eth2": {}}
}
.fi

Very basic config.

.nf
{
  "device": "team0",
  "runner": {"name": "activebackup"},
  "link_watch": {"name": "ethtool"},
  "ports": {
    "eth1": {
      "prio": -10,
      "sticky": true
    },
    "eth2": {
      "prio": 100
    }
  }
}
.fi

This config uses active-backup runner with ethtool linkwatch. Port eth2 has bigger priority. But sticky flag ensures that is eth1 becomes active, it stays active until it has link.

.nf
{
  "device": "team0",
  "runner": {"name": "activebackup"},
  "link_watch": {
    "name": "ethtool",
    "delay_up": 2500,
    "delay_down": 1000
  },
  "ports": {
    "eth1": {
      "prio": -10,
      "sticky": true
    },
    "eth2": {
      "prio": 100
    }
  }
}
.fi

Similar to the previous one. Ony difference that link changes are not proparated to runner immediately, but there are delays applied.

.nf
{
  "device": "team0",
  "runner": {"name": "activebackup"},
  "link_watch":	{
    "name": "arp_ping",
    "interval": 100,
    "missed_max": 30,
    "source_host": "192.168.23.2",
    "target_host": "192.168.23.1"
  },
  "ports": {
    "eth1": {
      "prio": -10,
      "sticky": true
    },
    "eth2": {
      "prio": 100
    }
  }
}
.fi

This config uses APR ping link watch.

.nf
{
"device": "team0",
"runner": {"name": "activebackup"},
"link_watch": [
  {
    "name": "arp_ping",
    "interval": 100,
    "missed_max": 30,
    "source_host": "192.168.23.2",
    "target_host": "192.168.23.1"
  },
  {
    "name": "arp_ping",
    "interval": 50,
    "missed_max": 20,
    "source_host": "192.168.24.2",
    "target_host": "192.168.24.1"
  }
],
"ports": {
  "eth1": {
    "prio": -10,
    "sticky": true
  },
  "eth2": {
    "prio": 100
    }
  }
}
.fi

Similar to the previous one, only this time two link watches are used at the same time.

.nf
{
  "device": "team0",
  "runner": {
    "name": "loadbalance",
    "tx_hash": ["eth", "ipv4", "ipv6"]
  },
  "ports": {"eth1": {}, "eth2": {}}
}
.fi

Config for hash-based passive TX load balancing.

.nf
{
  "device": "team0",
  "runner": {
    "name": "loadbalance",
    "tx_hash": ["eth", "ipv4", "ipv6"],
    "tx_balancer": {
      "name": "basic"
    }
  },
  "ports": {"eth1": {}, "eth2": {}}
}
.fi

Config for active TX load balancing using basic load balancer.

.nf
{
  "device": "team0",
  "runner": {
    "name": "lacp",
    "active": true,
    "fast_rate": true,
    "tx_hash": ["eth", "ipv4", "ipv6"]
  },
  "link_watch": {"name": "ethtool"},
  "ports": {"eth1": {}, "eth2": {}}
}
.fi

Config for connection to LACP capable counterpart.

.SH SEE ALSO
.BR teamd (8)

.SH AUTHOR
.PP
Jiri Pirko is the original author and current maintainer of libteam.
